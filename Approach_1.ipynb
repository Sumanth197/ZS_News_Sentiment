{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Approach_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooIQq2rW3vFd",
        "colab_type": "text"
      },
      "source": [
        "#Importing drive so as to access train and test files from Google Drive\n",
        "\n",
        "*  Google Colab provides a GPU which helps in training the model faster\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5sSTHnUD-oe",
        "colab_type": "code",
        "outputId": "51b55104-59da-4970-9480-0797bf52e447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgXz6lLS4Kd-",
        "colab_type": "text"
      },
      "source": [
        "# **Importing required libraries**\n",
        "****"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYkHFFiQEHBv",
        "colab_type": "code",
        "outputId": "d7115190-5c90-48ba-df08-346fad3b4b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.regularizers import L1L2\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqIJEqE94WI_",
        "colab_type": "text"
      },
      "source": [
        "##**Reading Train and Test Files from google drive and transforming them into a pandas dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAGVrOWuEQNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('gdrive/My Drive/train_file.csv')#, encoding='ISO-8859-1')\n",
        "test_data = pd.read_csv('gdrive/My Drive/test_file.csv')#, encoding='utf8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvMLnnap4huh",
        "colab_type": "text"
      },
      "source": [
        "**Changing the names of the columns into a lower case letters and white spaces are being replaced with underscore(''_\")**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9DN08dNIptV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.columns = train_data.columns.str.lower().str.rstrip()\n",
        "train_data.columns = train_data.columns.str.replace(' ', '_')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zztV4Mm043iq",
        "colab_type": "text"
      },
      "source": [
        "##Data Analysis\n",
        "\n",
        "\n",
        "*   Checking the length of each string present in the columns, Title and HeadLine, of the train_data dataframe\n",
        "*   Checking the existence of Null values in the columns of the train dataset\n",
        "*   Checking the Count of the NULL Values in each column of the train dataset\n",
        "*   Imputed the NULL Values of categorical column with Mode (Most Frequent)\n",
        "*   Shape of the train dataset and test dataset\n",
        "*   No : of Words, Unique_words, Stop_words in the columns, Title and Headline of the each dataframe\n",
        "*   Mean Length of words in the columns, Title and Headline, in each dataframe\n",
        "*   Unique values over the index axis in train_data dataframe\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxKnCn59tDBL",
        "colab_type": "code",
        "outputId": "0e733462-57aa-4fe9-e900-0a2b1182ec10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max(train_data[\"headline\"].str.len()), max(train_data[\"title\"].str.len())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(446, 170)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPK0vGs1FIMl",
        "colab_type": "code",
        "outputId": "36451794-439c-47b7-c753-8f7a223dd8f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idlink</th>\n",
              "      <th>title</th>\n",
              "      <th>headline</th>\n",
              "      <th>source</th>\n",
              "      <th>topic</th>\n",
              "      <th>publishdate</th>\n",
              "      <th>facebook</th>\n",
              "      <th>googleplus</th>\n",
              "      <th>linkedin</th>\n",
              "      <th>sentimenttitle</th>\n",
              "      <th>sentimentheadline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tr3CMgRv1N</td>\n",
              "      <td>Obama Lays Wreath at Arlington National Cemetery</td>\n",
              "      <td>Obama Lays Wreath at Arlington National Cemete...</td>\n",
              "      <td>USA TODAY</td>\n",
              "      <td>obama</td>\n",
              "      <td>2002-04-02 00:00:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.053300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wc81vGp8qZ</td>\n",
              "      <td>A Look at the Health of the Chinese Economy</td>\n",
              "      <td>Tim Haywood, investment director business-unit...</td>\n",
              "      <td>Bloomberg</td>\n",
              "      <td>economy</td>\n",
              "      <td>2008-09-20 00:00:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>-0.156386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>zNGH03CrZH</td>\n",
              "      <td>Nouriel Roubini: Global Economy Not Back to 2008</td>\n",
              "      <td>Nouriel Roubini, NYU professor and chairman at...</td>\n",
              "      <td>Bloomberg</td>\n",
              "      <td>economy</td>\n",
              "      <td>2012-01-28 00:00:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.425210</td>\n",
              "      <td>0.139754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3sM1H0W8ts</td>\n",
              "      <td>Finland GDP Expands In Q4</td>\n",
              "      <td>Finland's economy expanded marginally in the t...</td>\n",
              "      <td>RTT News</td>\n",
              "      <td>economy</td>\n",
              "      <td>2015-03-01 00:06:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.026064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wUbnxgvqaZ</td>\n",
              "      <td>Tourism, govt spending buoys Thai economy in J...</td>\n",
              "      <td>Tourism and public spending continued to boost...</td>\n",
              "      <td>The Nation - Thailand&amp;#39;s English news</td>\n",
              "      <td>economy</td>\n",
              "      <td>2015-03-01 00:11:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.141084</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       idlink  ... sentimentheadline\n",
              "0  Tr3CMgRv1N  ...         -0.053300\n",
              "1  Wc81vGp8qZ  ...         -0.156386\n",
              "2  zNGH03CrZH  ...          0.139754\n",
              "3  3sM1H0W8ts  ...          0.026064\n",
              "4  wUbnxgvqaZ  ...          0.141084\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hALtMQ-XTLDQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "0e6daffc-b1e8-431d-d914-924dea740cc6"
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDLink</th>\n",
              "      <th>Title</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Source</th>\n",
              "      <th>Topic</th>\n",
              "      <th>PublishDate</th>\n",
              "      <th>Facebook</th>\n",
              "      <th>GooglePlus</th>\n",
              "      <th>LinkedIn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tFrqIR6Chj</td>\n",
              "      <td>Sliding Economy: FG fights back with N3trn TSA...</td>\n",
              "      <td>With the 2016 budget now passed by the Nationa...</td>\n",
              "      <td>BusinessDay</td>\n",
              "      <td>economy</td>\n",
              "      <td>2016-03-29 01:41:12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DVAaGErjlF</td>\n",
              "      <td>Microsoft shows how HoloLens can bring distant...</td>\n",
              "      <td>A recent Microsoft Research video shows how th...</td>\n",
              "      <td>Daily Mail</td>\n",
              "      <td>microsoft</td>\n",
              "      <td>2016-03-29 01:41:27</td>\n",
              "      <td>121</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>OT9UIZm5M2</td>\n",
              "      <td>Microsoft’s Twitter Robot Praises Hitler, Trum...</td>\n",
              "      <td>* Microsoft teamed with Bing to create TayTwee...</td>\n",
              "      <td>EURweb</td>\n",
              "      <td>microsoft</td>\n",
              "      <td>2016-03-29 01:47:00</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lflGp3q2Fj</td>\n",
              "      <td>Flood of Central Bank Moves Can't Get World Ec...</td>\n",
              "      <td>Central bankers have managed to steer the worl...</td>\n",
              "      <td>Bloomberg via Yahoo! Finance</td>\n",
              "      <td>economy</td>\n",
              "      <td>2016-03-29 02:00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>zDYG0SoovZ</td>\n",
              "      <td>USD/JPY: bears lining up on mixed U.S. economy...</td>\n",
              "      <td>However, this streak of seven-day gains might ...</td>\n",
              "      <td>FXStreet</td>\n",
              "      <td>economy</td>\n",
              "      <td>2016-03-29 02:01:07</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       IDLink  ... LinkedIn\n",
              "0  tFrqIR6Chj  ...        1\n",
              "1  DVAaGErjlF  ...       13\n",
              "2  OT9UIZm5M2  ...        0\n",
              "3  lflGp3q2Fj  ...        3\n",
              "4  zDYG0SoovZ  ...        0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP5JpLJaTjk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.drop(['idlink','publishdate'],axis=1,inplace=True)\n",
        "\n",
        "#test_data.drop(['IDLink', 'PublishDate'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGIORnNKTWr-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "6ad45151-c67a-4d81-e25d-0b7fd23fba3b"
      },
      "source": [
        "train_data.dtypes"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title                 object\n",
              "headline              object\n",
              "source                object\n",
              "topic                 object\n",
              "facebook               int64\n",
              "googleplus             int64\n",
              "linkedin               int64\n",
              "sentimenttitle       float64\n",
              "sentimentheadline    float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld7lD1beErSB",
        "colab_type": "code",
        "outputId": "39ccecce-6bf9-4f7b-847f-0728bc1007c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "train_data.isnull().any()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title                False\n",
              "headline             False\n",
              "source                True\n",
              "topic                False\n",
              "facebook             False\n",
              "googleplus           False\n",
              "linkedin             False\n",
              "sentimenttitle       False\n",
              "sentimentheadline    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfhCoSklzHwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data['source'].value_counts(), train_data['topic'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R54o37gbw2hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Filling the NULL Values in Source with Mode\n",
        "\n",
        "train_data['source'].fillna(value=train_data['source'].value_counts().index[0],inplace =True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wys02MWoTist",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "9e15987f-f030-4c5d-835d-0d8d75957822"
      },
      "source": [
        "train_data.isnull().sum()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title                  0\n",
              "headline               0\n",
              "source               175\n",
              "topic                  0\n",
              "facebook               0\n",
              "googleplus             0\n",
              "linkedin               0\n",
              "sentimenttitle         0\n",
              "sentimentheadline      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47OaR9aWGki0",
        "colab_type": "code",
        "outputId": "8b696c77-a7a8-48d9-c798-bad0b8329c38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data.shape, test_data.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((55932, 9), (37288, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5tKsNKxgZR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data['headline_length'] = train_data[\"headline\"].str.len()\n",
        "train_data['title_length'] = train_data[\"title\"].str.len()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o1oOrbjU26W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# No. of words in the columns, Title and Headline, in each dataframe\n",
        "\n",
        "train_data[\"num_words_title\"] = train_data[\"title\"].apply(lambda x: len(str(x).split()))\n",
        "test_data[\"num_words_title\"] = test_data[\"Title\"].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "train_data[\"num_words_hLine\"] = train_data[\"headline\"].apply(lambda x: len(str(x).split()))\n",
        "test_data[\"num_words_hLine\"] = test_data[\"Headline\"].apply(lambda x: len(str(x).split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spiAllT6VL7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# No. of Unique Words in the columns, Title and Headline, in each dataframe\n",
        "\n",
        "train_data[\"num_unique_words_title\"] = train_data[\"title\"].apply(lambda x: len(str(x).split()))\n",
        "test_data[\"num_unique_words_title\"] = test_data[\"Title\"].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "train_data[\"num_unique_words_hLine\"] = train_data[\"headline\"].apply(lambda x: len(str(x).split()))\n",
        "test_data[\"num_unique_words_hLine\"] = test_data[\"Headline\"].apply(lambda x: len(str(x).split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CktvRlG0Vdni",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b1772036-5cd4-4b3a-cc11-d543027e2488"
      },
      "source": [
        "# No. of Stop_Words in the columns, Title and Headline, in each dataframe\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "eng_stopwords = set(stopwords.words(\"english\"))\n",
        "\n",
        "train_data[\"num_stop_words_title\"] = train_data[\"title\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
        "train_data[\"num_stop_words_hLine\"] = train_data['headline'].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
        "\n",
        "\n",
        "test_data[\"num_stop_words_title\"] = test_data[\"Title\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
        "test_data[\"num_stop_words_title\"] = test_data[\"Headline\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz9HN5FvWhDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "13c74b52-ab4e-4a79-d647-f43b63610893"
      },
      "source": [
        "# Mean Length of words in the columns, Title and Headline, in each dataframe\n",
        "\n",
        "train_data[\"mean_word_len_title\"] = train_data['title'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "train_data[\"mean_word_len_hLine\"] = train_data['headline'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "\n",
        "test_data[\"mean_word_len_title\"] = test_data['Title'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "test_data[\"mean_word_len_hLine\"] = test_data['Headline'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dff_9LDrW_Rs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "35a23939-770f-45e8-8aa6-83229610593a"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>headline</th>\n",
              "      <th>source</th>\n",
              "      <th>topic</th>\n",
              "      <th>facebook</th>\n",
              "      <th>googleplus</th>\n",
              "      <th>linkedin</th>\n",
              "      <th>sentimenttitle</th>\n",
              "      <th>sentimentheadline</th>\n",
              "      <th>num_words_title</th>\n",
              "      <th>num_words_hLine</th>\n",
              "      <th>num_unique_words_title</th>\n",
              "      <th>num_unique_words_hLine</th>\n",
              "      <th>num_stop_words_title</th>\n",
              "      <th>num_stop_words_hLine</th>\n",
              "      <th>mean_word_len_title</th>\n",
              "      <th>mean_word_len_hLine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Obama Lays Wreath at Arlington National Cemetery</td>\n",
              "      <td>Obama Lays Wreath at Arlington National Cemete...</td>\n",
              "      <td>USA TODAY</td>\n",
              "      <td>obama</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.053300</td>\n",
              "      <td>7</td>\n",
              "      <td>22</td>\n",
              "      <td>7</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.818182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A Look at the Health of the Chinese Economy</td>\n",
              "      <td>Tim Haywood, investment director business-unit...</td>\n",
              "      <td>Bloomberg</td>\n",
              "      <td>economy</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>-0.156386</td>\n",
              "      <td>9</td>\n",
              "      <td>22</td>\n",
              "      <td>9</td>\n",
              "      <td>22</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>3.888889</td>\n",
              "      <td>5.272727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nouriel Roubini: Global Economy Not Back to 2008</td>\n",
              "      <td>Nouriel Roubini, NYU professor and chairman at...</td>\n",
              "      <td>Bloomberg</td>\n",
              "      <td>economy</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.425210</td>\n",
              "      <td>0.139754</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5.125000</td>\n",
              "      <td>5.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Finland GDP Expands In Q4</td>\n",
              "      <td>Finland's economy expanded marginally in the t...</td>\n",
              "      <td>RTT News</td>\n",
              "      <td>economy</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.026064</td>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>6.652174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tourism, govt spending buoys Thai economy in J...</td>\n",
              "      <td>Tourism and public spending continued to boost...</td>\n",
              "      <td>The Nation - Thailand&amp;#39;s English news</td>\n",
              "      <td>economy</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.141084</td>\n",
              "      <td>8</td>\n",
              "      <td>27</td>\n",
              "      <td>8</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>5.625000</td>\n",
              "      <td>5.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ... mean_word_len_hLine\n",
              "0   Obama Lays Wreath at Arlington National Cemetery  ...            4.818182\n",
              "1        A Look at the Health of the Chinese Economy  ...            5.272727\n",
              "2   Nouriel Roubini: Global Economy Not Back to 2008  ...            5.900000\n",
              "3                          Finland GDP Expands In Q4  ...            6.652174\n",
              "4  Tourism, govt spending buoys Thai economy in J...  ...            5.333333\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i66XtSleXD-r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "5bedd611-ba7e-4079-942c-296894a072da"
      },
      "source": [
        "# Unique values over the index axis in train_data dataframe\n",
        "\n",
        "for i in train_data.columns:\n",
        "    print(i,' : ',train_data[i].nunique())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title  :  48963\n",
            "headline  :  52112\n",
            "source  :  4753\n",
            "topic  :  4\n",
            "facebook  :  2166\n",
            "googleplus  :  273\n",
            "linkedin  :  648\n",
            "sentimenttitle  :  10014\n",
            "sentimentheadline  :  27265\n",
            "num_words_title  :  24\n",
            "num_words_hLine  :  79\n",
            "num_unique_words_title  :  24\n",
            "num_unique_words_hLine  :  79\n",
            "num_stop_words_title  :  12\n",
            "num_stop_words_hLine  :  43\n",
            "mean_word_len_title  :  497\n",
            "mean_word_len_hLine  :  2353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWIFek_0bAYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data['source'].value_counts(), train_data['topic'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqk1S8LzbLqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data['Source'].value_counts(), test_data['Topic'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrehLSLMjI6H",
        "colab_type": "text"
      },
      "source": [
        "## Read the required columns for Predictions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Consider only 'Title' column for predictions of SentimentTitle\n",
        "\n",
        "*   Consider only 'HeadLine' column for predictions of SentimentHeadLine\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkD7BL9VIg_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_title = train_data[train_data['title'].notnull()]\n",
        "train_data_hLine = train_data[train_data['headline'].notnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm0cTfeQMzEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_title = train_data_title['title']\n",
        "Y_train_title = train_data_title['sentimenttitle']\n",
        "X_train_hLine = train_data_hLine['headline']\n",
        "Y_train_hLine = train_data_hLine['sentimentheadline']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kul2mtIqhSRA",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess text\n",
        "\n",
        "\n",
        "\n",
        "*   Remove punctuations from data.\n",
        "*   Apply lemmatization on words. Convert each word to its lemma.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyH_xiHJNV06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stemmer = SnowballStemmer(\"english\")\n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_data(X_train, lemma):\n",
        "    preprocessed_data = []\n",
        "    trans = str.maketrans('—/(){}-', ' ' * 7)\n",
        "    trans_punc = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "    for text in X_train:\n",
        "        #print(text)\n",
        "        text = text.lower().translate(trans)\n",
        "        text = text.translate(trans_punc)\n",
        "        text = re.sub(r\"\\'s\", \" is \", text)\n",
        "        text = re.sub(r\"n't\", \" not \", text)\n",
        "        text = [lemma.lemmatize(word) for word in text.split()]\n",
        "        text = [x for x in text if not any(c.isdigit() for c in x)]\n",
        "        preprocessed_data.append(' '.join(text))\n",
        "        #print(text)\n",
        "\n",
        "    return preprocessed_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmA253f2ODIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessed_data_t = preprocess_data(X_train_title, lemma)\n",
        "preprocessed_data_h = preprocess_data(X_train_hLine, lemma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO5E3bX4j6rN",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation for Keras Model Building\n",
        "\n",
        "\n",
        "\n",
        "*  **Initialize Tokenizer Objects**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTfOC2qNga6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_t = Tokenizer()\n",
        "\n",
        "t_t.fit_on_texts(preprocessed_data_t)\n",
        "encoded_lines_t = t_t.texts_to_sequences(preprocessed_data_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izSvWHi6w0hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_h = Tokenizer()\n",
        "\n",
        "t_h.fit_on_texts(preprocessed_data_h)\n",
        "encoded_lines_h = t_h.texts_to_sequences(preprocessed_data_h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC-PAFzWgpvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number_of_words_title = len(t_t.word_index) + 1\n",
        "number_of_words_hLine = len(t_h.word_index) + 1\n",
        "\n",
        "title_max_length_of_input = 200\n",
        "hLine_max_length_of_input = 500\n",
        "\n",
        "embedding_vector_length = 128\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQg6YpzIm_5j",
        "colab_type": "text"
      },
      "source": [
        "*   **Sequence Padding**\n",
        "\n",
        "*   **Train_Validation Split : Splitting the training data into train data and validation data**\n",
        "\n",
        "  *   Validation set plays a major role in improving the performance of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mItsT2puhMYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_t = sequence.pad_sequences(encoded_lines_t, title_max_length_of_input)\n",
        "X_train_t, X_valid_t, y_train_t, y_valid_t = train_test_split(X_train_t, Y_train_title, test_size=0.2, random_state=13)\n",
        "\n",
        "\n",
        "X_train_h = sequence.pad_sequences(encoded_lines_h, hLine_max_length_of_input)\n",
        "X_train_h, X_valid_h, y_train_h, y_valid_h = train_test_split(X_train_h, Y_train_hLine, test_size=0.2, random_state=13)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr3rVPcFlDca",
        "colab_type": "text"
      },
      "source": [
        "# Model Building for Predictions\n",
        "\n",
        "\n",
        "\n",
        "*   **TModel for predicting the SentimentTitle**\n",
        "  *    Compile the TModel\n",
        "  *    Summary of the TModel : Showing the architecture and Total Parameters of the TModel\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlYu6ee2MPBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=1e-8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hJ_hjOAhQUQ",
        "colab_type": "code",
        "outputId": "d2d6d632-8fe2-476a-efa2-8b7ce453d352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "Tmodel = Sequential()\n",
        "Tmodel.add(Embedding(number_of_words_title, embedding_vector_length, input_length = title_max_length_of_input))\n",
        "Tmodel.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "Tmodel.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "Tmodel.add(LSTM(50))\n",
        "Tmodel.add(Dense(1, activation = 'linear'))\n",
        "Tmodel.compile(loss='mean_absolute_error', optimizer= adam, metrics=['mean_absolute_error'])\n",
        "Tmodel.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0708 16:21:06.727590 139724375963520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0708 16:21:06.730935 139724375963520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0708 16:21:06.733603 139724375963520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0708 16:21:06.863080 139724375963520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0708 16:21:06.873550 139724375963520 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0708 16:21:07.705779 139724375963520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 128)          2842368   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 200, 100)          91600     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 200, 100)          80400     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 3,044,619\n",
            "Trainable params: 3,044,619\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w1jIRr3nf2n",
        "colab_type": "text"
      },
      "source": [
        "*   **HModel for predicting the SentimentHeadLine**\n",
        "  *    Compile the HModel\n",
        "  *    Summary of the HModel : Showing the architecture and Total Parameters of the HModel\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21kbM3ZRBpNt",
        "colab_type": "code",
        "outputId": "df9eb891-ae0b-4039-ed47-34e81166e6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "Hmodel = Sequential()\n",
        "Hmodel.add(Embedding(number_of_words_hLine, embedding_vector_length, input_length = hLine_max_length_of_input))\n",
        "Hmodel.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "Hmodel.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "Hmodel.add(LSTM(50))\n",
        "Hmodel.add(Dense(1, activation = 'linear'))\n",
        "Hmodel.compile(loss='mean_absolute_error', optimizer= adam, metrics=['mean_absolute_error'])\n",
        "Hmodel.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 128)          4918400   \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 500, 100)          91600     \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 500, 100)          80400     \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 5,120,651\n",
            "Trainable params: 5,120,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iuSgRySnmHR",
        "colab_type": "text"
      },
      "source": [
        "# Fitting the Train data to the Model\n",
        "\n",
        "\n",
        "\n",
        "*   **Fitting the train data of title to the TModel for predicting the SentimentTitle** \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0AU-xVbhanQ",
        "colab_type": "code",
        "outputId": "6771df54-729c-4328-eb73-4984e1a85c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Tmodel.fit(X_train_t, y_train_t, batch_size = 1024, epochs = 40, validation_data=(X_valid_t, y_valid_t),verbose = True, shuffle = True)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0708 16:21:09.178352 139724375963520 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0708 16:21:11.146214 139724375963520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 44745 samples, validate on 11187 samples\n",
            "Epoch 1/40\n",
            "44745/44745 [==============================] - 55s 1ms/step - loss: 0.0818 - mean_absolute_error: 0.0818 - val_loss: 0.0632 - val_mean_absolute_error: 0.0632\n",
            "Epoch 2/40\n",
            "44745/44745 [==============================] - 49s 1ms/step - loss: 0.0548 - mean_absolute_error: 0.0548 - val_loss: 0.0544 - val_mean_absolute_error: 0.0544\n",
            "Epoch 3/40\n",
            "44745/44745 [==============================] - 48s 1ms/step - loss: 0.0465 - mean_absolute_error: 0.0465 - val_loss: 0.0525 - val_mean_absolute_error: 0.0525\n",
            "Epoch 4/40\n",
            "44745/44745 [==============================] - 49s 1ms/step - loss: 0.0421 - mean_absolute_error: 0.0421 - val_loss: 0.0491 - val_mean_absolute_error: 0.0491\n",
            "Epoch 5/40\n",
            "44745/44745 [==============================] - 48s 1ms/step - loss: 0.0383 - mean_absolute_error: 0.0383 - val_loss: 0.0482 - val_mean_absolute_error: 0.0482\n",
            "Epoch 6/40\n",
            "44745/44745 [==============================] - 47s 1ms/step - loss: 0.0352 - mean_absolute_error: 0.0352 - val_loss: 0.0480 - val_mean_absolute_error: 0.0480\n",
            "Epoch 7/40\n",
            "44745/44745 [==============================] - 49s 1ms/step - loss: 0.0333 - mean_absolute_error: 0.0333 - val_loss: 0.0468 - val_mean_absolute_error: 0.0468\n",
            "Epoch 8/40\n",
            "44745/44745 [==============================] - 49s 1ms/step - loss: 0.0316 - mean_absolute_error: 0.0316 - val_loss: 0.0455 - val_mean_absolute_error: 0.0455\n",
            "Epoch 9/40\n",
            "44745/44745 [==============================] - 48s 1ms/step - loss: 0.0296 - mean_absolute_error: 0.0296 - val_loss: 0.0450 - val_mean_absolute_error: 0.0450\n",
            "Epoch 10/40\n",
            "44745/44745 [==============================] - 49s 1ms/step - loss: 0.0284 - mean_absolute_error: 0.0284 - val_loss: 0.0448 - val_mean_absolute_error: 0.0448\n",
            "Epoch 11/40\n",
            "44745/44745 [==============================] - 47s 1ms/step - loss: 0.0274 - mean_absolute_error: 0.0274 - val_loss: 0.0443 - val_mean_absolute_error: 0.0443\n",
            "Epoch 12/40\n",
            "44745/44745 [==============================] - 47s 1ms/step - loss: 0.0263 - mean_absolute_error: 0.0263 - val_loss: 0.0446 - val_mean_absolute_error: 0.0446\n",
            "Epoch 13/40\n",
            "44745/44745 [==============================] - 47s 1ms/step - loss: 0.0260 - mean_absolute_error: 0.0260 - val_loss: 0.0438 - val_mean_absolute_error: 0.0438\n",
            "Epoch 14/40\n",
            "44745/44745 [==============================] - 47s 1ms/step - loss: 0.0246 - mean_absolute_error: 0.0246 - val_loss: 0.0433 - val_mean_absolute_error: 0.0433\n",
            "Epoch 15/40\n",
            "44745/44745 [==============================] - 47s 1ms/step - loss: 0.0236 - mean_absolute_error: 0.0236 - val_loss: 0.0441 - val_mean_absolute_error: 0.0441\n",
            "Epoch 16/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0232 - mean_absolute_error: 0.0232 - val_loss: 0.0434 - val_mean_absolute_error: 0.0434\n",
            "Epoch 17/40\n",
            "44745/44745 [==============================] - 47s 1ms/step - loss: 0.0226 - mean_absolute_error: 0.0226 - val_loss: 0.0432 - val_mean_absolute_error: 0.0432\n",
            "Epoch 18/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0221 - mean_absolute_error: 0.0221 - val_loss: 0.0427 - val_mean_absolute_error: 0.0427\n",
            "Epoch 19/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0210 - mean_absolute_error: 0.0210 - val_loss: 0.0425 - val_mean_absolute_error: 0.0425\n",
            "Epoch 20/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0206 - mean_absolute_error: 0.0206 - val_loss: 0.0428 - val_mean_absolute_error: 0.0428\n",
            "Epoch 21/40\n",
            "44745/44745 [==============================] - 47s 1ms/step - loss: 0.0201 - mean_absolute_error: 0.0201 - val_loss: 0.0421 - val_mean_absolute_error: 0.0421\n",
            "Epoch 22/40\n",
            "44745/44745 [==============================] - 47s 1ms/step - loss: 0.0196 - mean_absolute_error: 0.0196 - val_loss: 0.0425 - val_mean_absolute_error: 0.0425\n",
            "Epoch 23/40\n",
            "44745/44745 [==============================] - 47s 1ms/step - loss: 0.0195 - mean_absolute_error: 0.0195 - val_loss: 0.0425 - val_mean_absolute_error: 0.0425\n",
            "Epoch 24/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0189 - mean_absolute_error: 0.0189 - val_loss: 0.0424 - val_mean_absolute_error: 0.0424\n",
            "Epoch 25/40\n",
            "44745/44745 [==============================] - 47s 1ms/step - loss: 0.0186 - mean_absolute_error: 0.0186 - val_loss: 0.0427 - val_mean_absolute_error: 0.0427\n",
            "Epoch 26/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0183 - mean_absolute_error: 0.0183 - val_loss: 0.0419 - val_mean_absolute_error: 0.0419\n",
            "Epoch 27/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0180 - mean_absolute_error: 0.0180 - val_loss: 0.0415 - val_mean_absolute_error: 0.0415\n",
            "Epoch 28/40\n",
            "44745/44745 [==============================] - 47s 1ms/step - loss: 0.0173 - mean_absolute_error: 0.0173 - val_loss: 0.0416 - val_mean_absolute_error: 0.0416\n",
            "Epoch 29/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0170 - mean_absolute_error: 0.0170 - val_loss: 0.0419 - val_mean_absolute_error: 0.0419\n",
            "Epoch 30/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0168 - mean_absolute_error: 0.0168 - val_loss: 0.0417 - val_mean_absolute_error: 0.0417\n",
            "Epoch 31/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0170 - mean_absolute_error: 0.0170 - val_loss: 0.0431 - val_mean_absolute_error: 0.0431\n",
            "Epoch 32/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0165 - mean_absolute_error: 0.0165 - val_loss: 0.0411 - val_mean_absolute_error: 0.0411\n",
            "Epoch 33/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0159 - mean_absolute_error: 0.0159 - val_loss: 0.0412 - val_mean_absolute_error: 0.0412\n",
            "Epoch 34/40\n",
            "44745/44745 [==============================] - 47s 1ms/step - loss: 0.0158 - mean_absolute_error: 0.0158 - val_loss: 0.0413 - val_mean_absolute_error: 0.0413\n",
            "Epoch 35/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0155 - mean_absolute_error: 0.0155 - val_loss: 0.0408 - val_mean_absolute_error: 0.0408\n",
            "Epoch 36/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0154 - mean_absolute_error: 0.0154 - val_loss: 0.0409 - val_mean_absolute_error: 0.0409\n",
            "Epoch 37/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0152 - mean_absolute_error: 0.0152 - val_loss: 0.0407 - val_mean_absolute_error: 0.0407\n",
            "Epoch 38/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0148 - mean_absolute_error: 0.0148 - val_loss: 0.0409 - val_mean_absolute_error: 0.0409\n",
            "Epoch 39/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0146 - mean_absolute_error: 0.0146 - val_loss: 0.0403 - val_mean_absolute_error: 0.0403\n",
            "Epoch 40/40\n",
            "44745/44745 [==============================] - 46s 1ms/step - loss: 0.0143 - mean_absolute_error: 0.0143 - val_loss: 0.0406 - val_mean_absolute_error: 0.0406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f13bc71d710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZrImyDlos0O",
        "colab_type": "text"
      },
      "source": [
        "*   **Fitting the train data of title to the TModel for predicting the SentimentTitle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFvoaxgvQusm",
        "colab_type": "code",
        "outputId": "f932da6a-a3f5-4441-f619-c0ff54e5f151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Hmodel.fit(X_train_h, y_train_h, batch_size = 1024, epochs = 40, validation_data=(X_valid_h, y_valid_h),verbose = True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 44745 samples, validate on 11187 samples\n",
            "Epoch 1/40\n",
            "44745/44745 [==============================] - 138s 3ms/step - loss: 0.1380 - mean_absolute_error: 0.1380 - val_loss: 0.1101 - val_mean_absolute_error: 0.1101\n",
            "Epoch 2/40\n",
            "44745/44745 [==============================] - 133s 3ms/step - loss: 0.1078 - mean_absolute_error: 0.1078 - val_loss: 0.1039 - val_mean_absolute_error: 0.1039\n",
            "Epoch 3/40\n",
            "44745/44745 [==============================] - 134s 3ms/step - loss: 0.0866 - mean_absolute_error: 0.0866 - val_loss: 0.0759 - val_mean_absolute_error: 0.0759\n",
            "Epoch 4/40\n",
            "44745/44745 [==============================] - 134s 3ms/step - loss: 0.0636 - mean_absolute_error: 0.0636 - val_loss: 0.0611 - val_mean_absolute_error: 0.0611\n",
            "Epoch 5/40\n",
            "44745/44745 [==============================] - 134s 3ms/step - loss: 0.0511 - mean_absolute_error: 0.0511 - val_loss: 0.0558 - val_mean_absolute_error: 0.0558\n",
            "Epoch 6/40\n",
            "44745/44745 [==============================] - 134s 3ms/step - loss: 0.0447 - mean_absolute_error: 0.0447 - val_loss: 0.0528 - val_mean_absolute_error: 0.0528\n",
            "Epoch 7/40\n",
            "44745/44745 [==============================] - 133s 3ms/step - loss: 0.0397 - mean_absolute_error: 0.0397 - val_loss: 0.0518 - val_mean_absolute_error: 0.0518\n",
            "Epoch 8/40\n",
            "44745/44745 [==============================] - 134s 3ms/step - loss: 0.0359 - mean_absolute_error: 0.0359 - val_loss: 0.0503 - val_mean_absolute_error: 0.0503\n",
            "Epoch 9/40\n",
            "44745/44745 [==============================] - 132s 3ms/step - loss: 0.0338 - mean_absolute_error: 0.0338 - val_loss: 0.0495 - val_mean_absolute_error: 0.0495\n",
            "Epoch 10/40\n",
            "44745/44745 [==============================] - 134s 3ms/step - loss: 0.0312 - mean_absolute_error: 0.0312 - val_loss: 0.0491 - val_mean_absolute_error: 0.0491\n",
            "Epoch 11/40\n",
            "44745/44745 [==============================] - 133s 3ms/step - loss: 0.0300 - mean_absolute_error: 0.0300 - val_loss: 0.0488 - val_mean_absolute_error: 0.0488\n",
            "Epoch 12/40\n",
            "44745/44745 [==============================] - 134s 3ms/step - loss: 0.0286 - mean_absolute_error: 0.0286 - val_loss: 0.0481 - val_mean_absolute_error: 0.0481\n",
            "Epoch 13/40\n",
            "44745/44745 [==============================] - 133s 3ms/step - loss: 0.0268 - mean_absolute_error: 0.0268 - val_loss: 0.0478 - val_mean_absolute_error: 0.0478\n",
            "Epoch 14/40\n",
            "44745/44745 [==============================] - 135s 3ms/step - loss: 0.0258 - mean_absolute_error: 0.0258 - val_loss: 0.0477 - val_mean_absolute_error: 0.0477\n",
            "Epoch 15/40\n",
            "44745/44745 [==============================] - 138s 3ms/step - loss: 0.0248 - mean_absolute_error: 0.0248 - val_loss: 0.0476 - val_mean_absolute_error: 0.0476\n",
            "Epoch 16/40\n",
            "44745/44745 [==============================] - 137s 3ms/step - loss: 0.0237 - mean_absolute_error: 0.0237 - val_loss: 0.0469 - val_mean_absolute_error: 0.0469\n",
            "Epoch 17/40\n",
            "44745/44745 [==============================] - 138s 3ms/step - loss: 0.0234 - mean_absolute_error: 0.0234 - val_loss: 0.0469 - val_mean_absolute_error: 0.0469\n",
            "Epoch 18/40\n",
            "44745/44745 [==============================] - 138s 3ms/step - loss: 0.0227 - mean_absolute_error: 0.0227 - val_loss: 0.0469 - val_mean_absolute_error: 0.0469\n",
            "Epoch 19/40\n",
            "44745/44745 [==============================] - 138s 3ms/step - loss: 0.0216 - mean_absolute_error: 0.0216 - val_loss: 0.0468 - val_mean_absolute_error: 0.0468\n",
            "Epoch 20/40\n",
            "44745/44745 [==============================] - 137s 3ms/step - loss: 0.0212 - mean_absolute_error: 0.0212 - val_loss: 0.0463 - val_mean_absolute_error: 0.0463\n",
            "Epoch 21/40\n",
            "44745/44745 [==============================] - 136s 3ms/step - loss: 0.0207 - mean_absolute_error: 0.0207 - val_loss: 0.0466 - val_mean_absolute_error: 0.0466\n",
            "Epoch 22/40\n",
            "44745/44745 [==============================] - 137s 3ms/step - loss: 0.0202 - mean_absolute_error: 0.0202 - val_loss: 0.0466 - val_mean_absolute_error: 0.0466\n",
            "Epoch 23/40\n",
            "44745/44745 [==============================] - 138s 3ms/step - loss: 0.0196 - mean_absolute_error: 0.0196 - val_loss: 0.0464 - val_mean_absolute_error: 0.0464\n",
            "Epoch 24/40\n",
            "44745/44745 [==============================] - 137s 3ms/step - loss: 0.0194 - mean_absolute_error: 0.0194 - val_loss: 0.0467 - val_mean_absolute_error: 0.0467\n",
            "Epoch 25/40\n",
            "44745/44745 [==============================] - 137s 3ms/step - loss: 0.0191 - mean_absolute_error: 0.0191 - val_loss: 0.0465 - val_mean_absolute_error: 0.0465\n",
            "Epoch 26/40\n",
            "44745/44745 [==============================] - 137s 3ms/step - loss: 0.0186 - mean_absolute_error: 0.0186 - val_loss: 0.0463 - val_mean_absolute_error: 0.0463\n",
            "Epoch 27/40\n",
            "44745/44745 [==============================] - 137s 3ms/step - loss: 0.0183 - mean_absolute_error: 0.0183 - val_loss: 0.0462 - val_mean_absolute_error: 0.0462\n",
            "Epoch 28/40\n",
            "44745/44745 [==============================] - 139s 3ms/step - loss: 0.0178 - mean_absolute_error: 0.0178 - val_loss: 0.0465 - val_mean_absolute_error: 0.0465\n",
            "Epoch 29/40\n",
            "44745/44745 [==============================] - 134s 3ms/step - loss: 0.0175 - mean_absolute_error: 0.0175 - val_loss: 0.0461 - val_mean_absolute_error: 0.0461\n",
            "Epoch 30/40\n",
            "44745/44745 [==============================] - 136s 3ms/step - loss: 0.0181 - mean_absolute_error: 0.0181 - val_loss: 0.0467 - val_mean_absolute_error: 0.0467\n",
            "Epoch 31/40\n",
            "44745/44745 [==============================] - 139s 3ms/step - loss: 0.0169 - mean_absolute_error: 0.0169 - val_loss: 0.0458 - val_mean_absolute_error: 0.0458\n",
            "Epoch 32/40\n",
            "44745/44745 [==============================] - 138s 3ms/step - loss: 0.0165 - mean_absolute_error: 0.0165 - val_loss: 0.0467 - val_mean_absolute_error: 0.0467\n",
            "Epoch 33/40\n",
            "44745/44745 [==============================] - 137s 3ms/step - loss: 0.0167 - mean_absolute_error: 0.0167 - val_loss: 0.0457 - val_mean_absolute_error: 0.0457\n",
            "Epoch 34/40\n",
            "44745/44745 [==============================] - 139s 3ms/step - loss: 0.0161 - mean_absolute_error: 0.0161 - val_loss: 0.0459 - val_mean_absolute_error: 0.0459\n",
            "Epoch 35/40\n",
            "44745/44745 [==============================] - 138s 3ms/step - loss: 0.0160 - mean_absolute_error: 0.0160 - val_loss: 0.0462 - val_mean_absolute_error: 0.0462\n",
            "Epoch 36/40\n",
            "44745/44745 [==============================] - 139s 3ms/step - loss: 0.0158 - mean_absolute_error: 0.0158 - val_loss: 0.0461 - val_mean_absolute_error: 0.0461\n",
            "Epoch 37/40\n",
            "44745/44745 [==============================] - 137s 3ms/step - loss: 0.0157 - mean_absolute_error: 0.0157 - val_loss: 0.0461 - val_mean_absolute_error: 0.0461\n",
            "Epoch 38/40\n",
            "44745/44745 [==============================] - 137s 3ms/step - loss: 0.0153 - mean_absolute_error: 0.0153 - val_loss: 0.0465 - val_mean_absolute_error: 0.0465\n",
            "Epoch 39/40\n",
            "44745/44745 [==============================] - 137s 3ms/step - loss: 0.0154 - mean_absolute_error: 0.0154 - val_loss: 0.0463 - val_mean_absolute_error: 0.0463\n",
            "Epoch 40/40\n",
            "44745/44745 [==============================] - 137s 3ms/step - loss: 0.0149 - mean_absolute_error: 0.0149 - val_loss: 0.0455 - val_mean_absolute_error: 0.0455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f135cf03a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLjpYoVFo3BV",
        "colab_type": "text"
      },
      "source": [
        "# Conversion of Text Form Test Data into Vector Form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPbcVYjvhtRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_title = test_data['Title']\n",
        "X_test_title = preprocess_data(X_test_title, lemma)\n",
        "X_test_title = t_t.texts_to_sequences(X_test_title)\n",
        "X_test_title = sequence.pad_sequences(X_test_title, title_max_length_of_input)\n",
        "\n",
        "\n",
        "X_test_hLine = test_data['Headline']\n",
        "X_test_hLine = preprocess_data(X_test_hLine, lemma)\n",
        "X_test_hLine = t_h.texts_to_sequences(X_test_hLine)\n",
        "X_test_hLine = sequence.pad_sequences(X_test_hLine, hLine_max_length_of_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCwvGta_pPl_",
        "colab_type": "text"
      },
      "source": [
        "# Predict the output of the Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoNcYBJqiPnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T_output = Tmodel.predict(X_test_title, 1024).flatten()\n",
        "\n",
        "H_output = Hmodel.predict(X_test_hLine, 1024).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwWdsTj8ppKo",
        "colab_type": "text"
      },
      "source": [
        "# Importing the results into the CSV File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bisj_DtZw5OR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_df = pd.DataFrame({'IDLink': test_data['IDLink'],'SentimentTitle': T_output, 'SentimentHeadline':H_output})\n",
        "test_data_df.to_csv('gdrive/My Drive/Approach_1_file.csv', index=False, columns=['IDLink','SentimentTitle', 'SentimentHeadline'])\n",
        "test_data_df.to_csv('Output_file.csv', index=False, columns=['IDLink','SentimentTitle', 'SentimentHeadline'])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}