{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Approach_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooIQq2rW3vFd",
        "colab_type": "text"
      },
      "source": [
        "#Importing drive so as to access train and test files from Google Drive\n",
        "\n",
        "*  Google Colab provides a GPU which helps in training the model faster\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5sSTHnUD-oe",
        "colab_type": "code",
        "outputId": "3df9d3a7-042e-4bc3-d87d-178c28e21139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgXz6lLS4Kd-",
        "colab_type": "text"
      },
      "source": [
        "# **Importing required libraries**\n",
        "****"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYkHFFiQEHBv",
        "colab_type": "code",
        "outputId": "3a16c41d-f5ea-4b19-e4de-d47da54ebb4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.regularizers import L1L2\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqIJEqE94WI_",
        "colab_type": "text"
      },
      "source": [
        "##**Reading Train and Test Files from google drive and transforming them into a pandas dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAGVrOWuEQNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('gdrive/My Drive/train_file.csv')#, encoding='ISO-8859-1')\n",
        "test_data = pd.read_csv('gdrive/My Drive/test_file.csv')#, encoding='utf8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvMLnnap4huh",
        "colab_type": "text"
      },
      "source": [
        "**Changing the names of the columns into a lower case letters and white spaces are being replaced with underscore(''_\")**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9DN08dNIptV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.columns = train_data.columns.str.lower().str.rstrip()\n",
        "train_data.columns = train_data.columns.str.replace(' ', '_')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zztV4Mm043iq",
        "colab_type": "text"
      },
      "source": [
        "##Data Analysis\n",
        "\n",
        "\n",
        "*   Checking the length of each string present in the columns, Title and HeadLine, of the train dataframe\n",
        "*   Checking the existence of Null values in the columns of the train dataset\n",
        "*   Checking the Count of the NULL Values in each column of the train dataset\n",
        "*   Shape of the train dataset and test dataset\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxKnCn59tDBL",
        "colab_type": "code",
        "outputId": "ae82245b-5993-44c8-fff1-5c7c3e63f189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max(train_data[\"headline\"].str.len()), max(train_data[\"title\"].str.len())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(446, 170)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPK0vGs1FIMl",
        "colab_type": "code",
        "outputId": "6d4d8bd5-39e6-4c01-c7b1-97acd6ce2e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_data.head(20)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idlink</th>\n",
              "      <th>title</th>\n",
              "      <th>headline</th>\n",
              "      <th>source</th>\n",
              "      <th>topic</th>\n",
              "      <th>publishdate</th>\n",
              "      <th>facebook</th>\n",
              "      <th>googleplus</th>\n",
              "      <th>linkedin</th>\n",
              "      <th>sentimenttitle</th>\n",
              "      <th>sentimentheadline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tr3CMgRv1N</td>\n",
              "      <td>Obama Lays Wreath at Arlington National Cemetery</td>\n",
              "      <td>Obama Lays Wreath at Arlington National Cemete...</td>\n",
              "      <td>USA TODAY</td>\n",
              "      <td>obama</td>\n",
              "      <td>2002-04-02 00:00:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.053300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wc81vGp8qZ</td>\n",
              "      <td>A Look at the Health of the Chinese Economy</td>\n",
              "      <td>Tim Haywood, investment director business-unit...</td>\n",
              "      <td>Bloomberg</td>\n",
              "      <td>economy</td>\n",
              "      <td>2008-09-20 00:00:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>-0.156386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>zNGH03CrZH</td>\n",
              "      <td>Nouriel Roubini: Global Economy Not Back to 2008</td>\n",
              "      <td>Nouriel Roubini, NYU professor and chairman at...</td>\n",
              "      <td>Bloomberg</td>\n",
              "      <td>economy</td>\n",
              "      <td>2012-01-28 00:00:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.425210</td>\n",
              "      <td>0.139754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3sM1H0W8ts</td>\n",
              "      <td>Finland GDP Expands In Q4</td>\n",
              "      <td>Finland's economy expanded marginally in the t...</td>\n",
              "      <td>RTT News</td>\n",
              "      <td>economy</td>\n",
              "      <td>2015-03-01 00:06:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.026064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wUbnxgvqaZ</td>\n",
              "      <td>Tourism, govt spending buoys Thai economy in J...</td>\n",
              "      <td>Tourism and public spending continued to boost...</td>\n",
              "      <td>The Nation - Thailand&amp;#39;s English news</td>\n",
              "      <td>economy</td>\n",
              "      <td>2015-03-01 00:11:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.141084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1P7kLrnWEp</td>\n",
              "      <td>Intellitec Solutions to Host 13th Annual Sprin...</td>\n",
              "      <td>Over 100 attendees expected to see latest vers...</td>\n",
              "      <td>PRWeb</td>\n",
              "      <td>microsoft</td>\n",
              "      <td>2015-03-01 00:19:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.075378</td>\n",
              "      <td>0.036773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lKg2pImhCl</td>\n",
              "      <td>Monday, 29 Feb 2016</td>\n",
              "      <td>RAMALLAH, February 25, 2016 (WAFA) - Palestine...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>palestine</td>\n",
              "      <td>2016-02-28 14:03:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.005906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>X2KssRh8hS</td>\n",
              "      <td>Obama, stars pay a musical tribute to Ray Charles</td>\n",
              "      <td>First lady Michelle Obama speaks in the State ...</td>\n",
              "      <td>Coast Reporter</td>\n",
              "      <td>obama</td>\n",
              "      <td>2015-03-01 00:45:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.103003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>xCHOHAl8v8</td>\n",
              "      <td>Fire claims more than 100-year-old barn in Han...</td>\n",
              "      <td>A Hancock County man lost a barn early Monday ...</td>\n",
              "      <td>WTHR Indianapolis</td>\n",
              "      <td>palestine</td>\n",
              "      <td>2015-03-01 01:20:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.173925</td>\n",
              "      <td>-0.050185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>OR6Xuthveg</td>\n",
              "      <td>Microsoft's new Windows 10 ad targets Apple</td>\n",
              "      <td>New Delhi, Feb.29 : Technology giant Microsoft...</td>\n",
              "      <td>New Kerala</td>\n",
              "      <td>microsoft</td>\n",
              "      <td>2015-03-01 01:32:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.059536</td>\n",
              "      <td>-0.081715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Xj3f9iYOaj</td>\n",
              "      <td>Microsoft Project Centennial seen with “univer...</td>\n",
              "      <td>Microsoft may have burned off one bridge, but ...</td>\n",
              "      <td>SlashGear</td>\n",
              "      <td>microsoft</td>\n",
              "      <td>2015-03-01 02:14:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>XP3QOFGatF</td>\n",
              "      <td>Microsoft sneaks onto Android while Android sn...</td>\n",
              "      <td>The platform battles are back MWC16 +Analysis ...</td>\n",
              "      <td>The Register</td>\n",
              "      <td>microsoft</td>\n",
              "      <td>2015-03-01 02:15:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.052670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>SMpjcX5Owv</td>\n",
              "      <td>Greek economy grows 0.1 pct q/q in fourth quarter</td>\n",
              "      <td>Greece's economy expanded by 0.1 percent in la...</td>\n",
              "      <td>Reuters via Yahoo! Finance</td>\n",
              "      <td>economy</td>\n",
              "      <td>2015-03-01 02:16:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.375259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1cSzijNBpx</td>\n",
              "      <td>Big data and the Internet of Things to add £32...</td>\n",
              "      <td>Big data analytics and the Internet of Things ...</td>\n",
              "      <td>Information Age</td>\n",
              "      <td>economy</td>\n",
              "      <td>2015-03-01 02:18:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.063205</td>\n",
              "      <td>0.038986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>iKGS4umScz</td>\n",
              "      <td>HoloLens dev edition costs £2,000 with new Con...</td>\n",
              "      <td>Microsoft’s AR headset is being made available...</td>\n",
              "      <td>Metro</td>\n",
              "      <td>microsoft</td>\n",
              "      <td>2015-03-01 02:18:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.079434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>hgh3ircFGZ</td>\n",
              "      <td>Microsoft Word for Mac 2016 review: A subtle y...</td>\n",
              "      <td>What is A + B? Welcome to our review of Word f...</td>\n",
              "      <td>Macworld UK</td>\n",
              "      <td>microsoft</td>\n",
              "      <td>2015-03-01 02:54:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.023883</td>\n",
              "      <td>-0.032275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3o1xzPpavu</td>\n",
              "      <td>Microsoft Band 2 gains appeal with lower price</td>\n",
              "      <td>The Microsoft Band 2 hit the market in late 20...</td>\n",
              "      <td>SlashGear</td>\n",
              "      <td>microsoft</td>\n",
              "      <td>2015-03-01 03:10:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.070868</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ukPNQD9k4r</td>\n",
              "      <td>Microsoft prepares to unleash Office 2016 full...</td>\n",
              "      <td>It seems that Microsoft is getting ready to pu...</td>\n",
              "      <td>TechRadar</td>\n",
              "      <td>microsoft</td>\n",
              "      <td>2015-03-01 03:10:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>5rnVCZqWr2</td>\n",
              "      <td>Greek economy shrank 0.3 percent last year but...</td>\n",
              "      <td>Greece's economy expanded slightly in the last...</td>\n",
              "      <td>Reuters via Yahoo! Finance</td>\n",
              "      <td>economy</td>\n",
              "      <td>2015-03-01 03:15:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.085645</td>\n",
              "      <td>-0.099531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>CZLVHanbC2</td>\n",
              "      <td>Sweden's economy is on fire — but here's why t...</td>\n",
              "      <td>Sweden's economy is on a massive tear, but for...</td>\n",
              "      <td>Business Insider UK Finance via Yahoo Canada F...</td>\n",
              "      <td>economy</td>\n",
              "      <td>2015-03-01 03:15:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.014174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        idlink  ... sentimentheadline\n",
              "0   Tr3CMgRv1N  ...         -0.053300\n",
              "1   Wc81vGp8qZ  ...         -0.156386\n",
              "2   zNGH03CrZH  ...          0.139754\n",
              "3   3sM1H0W8ts  ...          0.026064\n",
              "4   wUbnxgvqaZ  ...          0.141084\n",
              "5   1P7kLrnWEp  ...          0.036773\n",
              "6   lKg2pImhCl  ...         -0.005906\n",
              "7   X2KssRh8hS  ...          0.103003\n",
              "8   xCHOHAl8v8  ...         -0.050185\n",
              "9   OR6Xuthveg  ...         -0.081715\n",
              "10  Xj3f9iYOaj  ...          0.002550\n",
              "11  XP3QOFGatF  ...          0.052670\n",
              "12  SMpjcX5Owv  ...         -0.375259\n",
              "13  1cSzijNBpx  ...          0.038986\n",
              "14  iKGS4umScz  ...          0.079434\n",
              "15  hgh3ircFGZ  ...         -0.032275\n",
              "16  3o1xzPpavu  ...          0.000000\n",
              "17  ukPNQD9k4r  ...          0.001367\n",
              "18  5rnVCZqWr2  ...         -0.099531\n",
              "19  CZLVHanbC2  ...         -0.014174\n",
              "\n",
              "[20 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld7lD1beErSB",
        "colab_type": "code",
        "outputId": "de608980-6452-4979-efe5-342566d105c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "train_data.isnull().any(), train_data.isnull().sum()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(idlink               False\n",
              " title                False\n",
              " headline             False\n",
              " source               False\n",
              " topic                False\n",
              " publishdate          False\n",
              " facebook             False\n",
              " googleplus           False\n",
              " linkedin             False\n",
              " sentimenttitle       False\n",
              " sentimentheadline    False\n",
              " dtype: bool, idlink               0\n",
              " title                0\n",
              " headline             0\n",
              " source               0\n",
              " topic                0\n",
              " publishdate          0\n",
              " facebook             0\n",
              " googleplus           0\n",
              " linkedin             0\n",
              " sentimenttitle       0\n",
              " sentimentheadline    0\n",
              " dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXeZOF9GyGgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data['source'].fillna(value=train_data['source'].value_counts().index[0],inplace =True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47OaR9aWGki0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.shape, test_data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrehLSLMjI6H",
        "colab_type": "text"
      },
      "source": [
        "## Read the required columns for Predictions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Consider only 'Title' column for predictions of SentimentTitle\n",
        "\n",
        "*   Consider only 'HeadLine' column for predictions of SentimentHeadLine\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkD7BL9VIg_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_title = train_data[train_data['title'].notnull()]\n",
        "train_data_hLine = train_data[train_data['headline'].notnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm0cTfeQMzEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_title = train_data_title['title']\n",
        "Y_train_title = train_data_title['sentimenttitle']\n",
        "X_train_hLine = train_data_hLine['headline']\n",
        "Y_train_hLine = train_data_hLine['sentimentheadline']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kul2mtIqhSRA",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess text\n",
        "\n",
        "\n",
        "\n",
        "*   Remove punctuations from data.\n",
        "*   Apply lemmatization on words. Convert each word to its lemma.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyH_xiHJNV06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stemmer = SnowballStemmer(\"english\")\n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_data(X_train, lemma):\n",
        "    preprocessed_data = []\n",
        "    trans = str.maketrans('—/(){}-', ' ' * 7)\n",
        "    trans_punc = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "    for text in X_train:\n",
        "        #print(text)\n",
        "        text = text.lower().translate(trans)\n",
        "        text = text.translate(trans_punc)\n",
        "        text = [lemma.lemmatize(word) for word in text.split()]\n",
        "        text = [x for x in text if not any(c.isdigit() for c in x)]\n",
        "        preprocessed_data.append(' '.join(text))\n",
        "        #print(text)\n",
        "\n",
        "    return preprocessed_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmA253f2ODIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessed_data_t = preprocess_data(X_train_title, lemma)\n",
        "preprocessed_data_h = preprocess_data(X_train_hLine, lemma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO5E3bX4j6rN",
        "colab_type": "text"
      },
      "source": [
        "# Tfidf Vectorizer - Transform text into vector\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "777gQVS0DJPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer_t = TfidfVectorizer(max_df=0.95, min_df=2, max_features=5000, stop_words='english', ngram_range=(1, 3))\n",
        "vectorizer_t.fit(X_train_title)\n",
        "\n",
        "vectorizer_h = TfidfVectorizer(max_df=0.95, min_df=2, max_features=5000, stop_words='english', ngram_range=(1, 3))\n",
        "vectorizer_h.fit(X_train_hLine)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUGU7uV7DP5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_title = vectorizer_t.transform(X_train_title).toarray()\n",
        "\n",
        "X_train_hLine = vectorizer_h.transform(X_train_hLine).toarray()\n",
        "\n",
        "X_train_title.shape, X_train_hLine.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQg6YpzIm_5j",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   **Train_Validation Split : Splitting the training data into train data and validation data**\n",
        "\n",
        "  *   Validation set plays a major role in improving the performance of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mItsT2puhMYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_train_t, X_valid_t, y_train_t, y_valid_t = train_test_split(X_train_title, Y_train_title, test_size=0.2, random_state=13)\n",
        "\n",
        "X_train_h, X_valid_h, y_train_h, y_valid_h = train_test_split(X_train_hLine, Y_train_hLine, test_size=0.2, random_state=13)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr3rVPcFlDca",
        "colab_type": "text"
      },
      "source": [
        "# Model Building for Predictions\n",
        "\n",
        "\n",
        "\n",
        "*   **TModel for predicting the SentimentTitle**\n",
        "  *    Compile the TModel\n",
        "  *    Summary of the TModel : Showing the architecture and Total Parameters of the TModel\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlYu6ee2MPBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hJ_hjOAhQUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "Tmodel = Sequential()\n",
        "Tmodel.add(Dense(128, activation='relu', input_dim=5000))\n",
        "Tmodel.add(Dropout(0.2))\n",
        "Tmodel.add(Dense(128, activation='relu'))\n",
        "Tmodel.add(Dropout(0.2))\n",
        "Tmodel.add(Dense(128, activation='relu'))\n",
        "Tmodel.add(Dense(128, activation='relu'))\n",
        "Tmodel.add(Dropout(0.2))\n",
        "Tmodel.add(Dense(64, activation='relu'))\n",
        "Tmodel.add(Dense(1,\n",
        "                activation='linear',\n",
        "                kernel_regularizer=L1L2(l1=0.02, l2=0.03)))\n",
        "Tmodel.compile(loss='mean_absolute_error', optimizer= adam, metrics=['mean_absolute_error'])\n",
        "Tmodel.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w1jIRr3nf2n",
        "colab_type": "text"
      },
      "source": [
        "*   **HModel for predicting the SentimentHeadLine**\n",
        "  *    Compile the HModel\n",
        "  *    Summary of the HModel : Showing the architecture and Total Parameters of the HModel\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21kbM3ZRBpNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "Hmodel = Sequential()\n",
        "Hmodel.add(Dense(128, activation='relu', input_dim=5000))\n",
        "Hmodel.add(Dropout(0.2))\n",
        "Hmodel.add(Dense(128, activation='relu'))\n",
        "Hmodel.add(Dropout(0.2))\n",
        "Hmodel.add(Dense(128, activation='relu'))\n",
        "Hmodel.add(Dense(128, activation='relu'))\n",
        "Hmodel.add(Dense(64, activation='relu'))\n",
        "Hmodel.add(Dense(1,\n",
        "                activation='linear',\n",
        "                kernel_regularizer=L1L2(l1=0.02, l2=0.03)))\n",
        "Hmodel.compile(loss='mean_absolute_error', optimizer= adam, metrics=['mean_absolute_error'])\n",
        "Hmodel.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iuSgRySnmHR",
        "colab_type": "text"
      },
      "source": [
        "# Fitting the Train data to the Model\n",
        "\n",
        "\n",
        "\n",
        "*   **Fitting the train data of title to the TModel for predicting the SentimentTitle** \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0AU-xVbhanQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Tmodel.fit(X_train_t, y_train_t, batch_size = 1024, epochs = 30, validation_data=(X_valid_t, y_valid_t),verbose = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZrImyDlos0O",
        "colab_type": "text"
      },
      "source": [
        "*   **Fitting the train data of title to the TModel for predicting the SentimentTitle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFvoaxgvQusm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Hmodel.fit(X_train_h, y_train_h, batch_size = 1024, epochs = 30, validation_data=(X_valid_h, y_valid_h),verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLjpYoVFo3BV",
        "colab_type": "text"
      },
      "source": [
        "# Conversion of Text Form Test Data into Vector Form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPbcVYjvhtRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_title = test_data['Title']\n",
        "X_test_title = preprocess_data(X_test_title, lemma)\n",
        "X_test_title = vectorizer_t.transform(X_test_title).toarray()\n",
        "\n",
        "\n",
        "X_test_hLine = test_data['Headline']\n",
        "X_test_hLine = preprocess_data(X_test_hLine, lemma)\n",
        "X_test_hLine = vectorizer_h.transform(X_test_hLine).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCwvGta_pPl_",
        "colab_type": "text"
      },
      "source": [
        "# Predict the output of the Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoNcYBJqiPnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T_output = Tmodel.predict(X_test_title, 1024).flatten()\n",
        "\n",
        "H_output = Hmodel.predict(X_test_hLine, 1024).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwWdsTj8ppKo",
        "colab_type": "text"
      },
      "source": [
        "# Importing the results into the CSV File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bisj_DtZw5OR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_df = pd.DataFrame({'IDLink': test_data['IDLink'],'SentimentTitle': T_output, 'SentimentHeadline':H_output})\n",
        "test_data_df.to_csv('gdrive/My Drive/Approach_2_file.csv', index=False, columns=['IDLink','SentimentTitle', 'SentimentHeadline'])\n",
        "test_data_df.to_csv('Output_file.csv', index=False, columns=['IDLink','SentimentTitle', 'SentimentHeadline'])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}